from flask import Flask, request, jsonify, Response
from flask_cors import CORS
import json
from google import genai
from typing import List, Dict, Any
import os
from datetime import datetime
import time
import threading
from prompt_manager import prompt_manager
from workflow_dashboard import workflow_monitor
from mock_data_generator import mock_generator
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

app = Flask(__name__)
CORS(app)  # Enable CORS for all routes

# Application mode configuration
APP_MODE = os.getenv('APP_MODE', 'demo').lower()
print(f"üöÄ Application running in {APP_MODE.upper()} mode")

# Gemini API configuration (only for production mode)
client = None
if APP_MODE == 'production':
    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
    if not GEMINI_API_KEY:
        raise ValueError("GEMINI_API_KEY environment variable is required for production mode")
    client = genai.Client(api_key=GEMINI_API_KEY)
    print("‚úÖ Gemini API client initialized")
else:
    print("üé≠ Running in demo mode with mock data")

class ChatMessage:
    def __init__(self, role: str, content: str):
        self.role = role
        self.content = content

class EvaluationConsultant:
    def __init__(self):
        # Individual expert profiles that can be combined
        self.expert_profiles = {
            '3d_graphics': {
                'title': '3D Computer Graphics & Artistic Rendering Specialist',
                'emoji': 'üé®',
                'expertise': 'Deep expertise in 3D modeling, neural rendering, photogrammetry, and digital art creation pipelines',
                'technical_focus': 'Identity-preserving 3D generation, PBR material decomposition, mesh topology optimization, UV unwrapping algorithms',
                'domains': ['q_figurine_3d', 'gaming', 'ar_vr']
            },
            'autonomous_systems': {
                'title': 'Autonomous Vehicle Systems Engineer',
                'emoji': 'üöó',
                'expertise': 'Expertise in LIDAR, computer vision, sensor fusion, real-time systems, and automotive safety standards',
                'technical_focus': 'Perception algorithms, path planning, control systems, safety-critical software, V2X communication',
                'domains': ['autonomous_driving', 'robotics']
            },
            'medical_ai': {
                'title': 'Medical Imaging & Clinical Diagnostics Specialist',
                'emoji': 'üè•',
                'expertise': 'Deep knowledge of medical imaging modalities, pathology, clinical workflows, and healthcare standards',
                'technical_focus': 'DICOM processing, anatomical structure detection, disease classification, clinical decision support',
                'domains': ['medical_diagnosis', 'healthcare']
            },
            'ai_researcher': {
                'title': 'AI/ML Model Architecture Researcher',
                'emoji': 'üî¨',
                'expertise': 'Advanced knowledge of neural networks, diffusion models, transformer architectures, and evaluation methodologies',
                'technical_focus': 'Model evaluation methodologies, benchmark design, performance metrics, technical feasibility analysis',
                'domains': ['all']
            },
            'user_experience': {
                'title': 'Product Experience & User Research Specialist',
                'emoji': 'üë•',
                'expertise': 'Understanding user psychology, product-market fit, usability testing, and customer journey optimization',
                'technical_focus': 'User journey mapping, emotional value assessment, usability testing, market positioning',
                'domains': ['all']
            },
            'safety_critical': {
                'title': 'Safety-Critical AI Systems Researcher',
                'emoji': 'üõ°Ô∏è',
                'expertise': 'Advanced knowledge of robust ML, uncertainty quantification, formal verification, and edge case handling',
                'technical_focus': 'Safety metrics, adversarial robustness, model interpretability, real-world validation protocols',
                'domains': ['autonomous_driving', 'medical_diagnosis', 'aviation']
            },
            'healthcare_workflow': {
                'title': 'Healthcare Provider & Patient Experience Specialist', 
                'emoji': '‚öïÔ∏è',
                'expertise': 'Understanding clinician workflows, patient concerns, healthcare accessibility, and medical ethics',
                'technical_focus': 'Clinical usability, patient safety, workflow integration, health equity considerations',
                'domains': ['medical_diagnosis', 'healthcare']
            }
        }

        # Legacy domain configs for backward compatibility
        self.role_configs = {
            'q_figurine_3d': {
                'domain_specialist': {
                    'title': '3D Computer Graphics & Artistic Rendering Specialist',
                    'expertise': 'Deep expertise in 3D modeling, neural rendering, photogrammetry, and digital art creation pipelines',
                    'technical_focus': 'Identity-preserving 3D generation, PBR material decomposition, mesh topology optimization, UV unwrapping algorithms'
                },
                'technical_researcher': {
                    'title': 'AI/ML Model Architecture Researcher', 
                    'expertise': 'Advanced knowledge of neural networks, diffusion models, NeRFs, and multi-modal AI systems',
                    'technical_focus': 'Model evaluation methodologies, benchmark design, performance metrics, technical feasibility analysis'
                },
                'user_advocate': {
                    'title': 'Consumer Product Experience Specialist',
                    'expertise': 'Understanding end-user psychology, digital collectibles market, social media culture, and personalization desires',
                    'technical_focus': 'User journey mapping, emotional value assessment, usability testing, market positioning'
                },
                'domain': '3D Figurine Generation from Photos',
                'target_users': 'Social media users wanting personalized 3D avatars/collectibles',
                'business_context': 'B2C product with focus on viral sharing, personalization, and emotional connection'
            },
            'autonomous_driving': {
                'domain_specialist': {
                    'title': 'Autonomous Vehicle Systems Engineer',
                    'expertise': 'Expertise in LIDAR, computer vision, sensor fusion, real-time systems, and automotive safety standards',
                    'technical_focus': 'Perception algorithms, path planning, control systems, safety-critical software, V2X communication'
                },
                'technical_researcher': {
                    'title': 'Safety-Critical AI Systems Researcher',
                    'expertise': 'Advanced knowledge of robust ML, uncertainty quantification, formal verification, and edge case handling',
                    'technical_focus': 'Safety metrics, adversarial robustness, model interpretability, real-world validation protocols'
                },
                'user_advocate': {
                    'title': 'Automotive User Experience & Safety Specialist',
                    'expertise': 'Understanding driver psychology, passenger comfort, regulatory compliance, and public trust in autonomous systems',
                    'technical_focus': 'Human-vehicle interaction, trust calibration, accessibility design, emergency scenarios'
                },
                'domain': 'Autonomous Vehicle Perception and Control',
                'target_users': 'Drivers, passengers, pedestrians, and regulatory bodies',
                'business_context': 'Safety-critical B2C/B2B product requiring regulatory approval and public trust'
            },
            'medical_diagnosis': {
                'domain_specialist': {
                    'title': 'Medical Imaging & Clinical Diagnostics Specialist',
                    'expertise': 'Deep knowledge of medical imaging modalities, pathology, clinical workflows, and healthcare standards',
                    'technical_focus': 'DICOM processing, anatomical structure detection, disease classification, clinical decision support'
                },
                'technical_researcher': {
                    'title': 'Healthcare AI Validation Researcher',
                    'expertise': 'Expertise in clinical trial design, FDA validation protocols, bias detection, and medical AI ethics',
                    'technical_focus': 'Clinical validation metrics, demographic bias analysis, interpretability for clinicians, regulatory compliance'
                },
                'user_advocate': {
                    'title': 'Healthcare Provider & Patient Experience Specialist',
                    'expertise': 'Understanding clinician workflows, patient concerns, healthcare accessibility, and medical ethics',
                    'technical_focus': 'Clinical usability, patient safety, workflow integration, health equity considerations'
                },
                'domain': 'AI-Assisted Medical Diagnosis',
                'target_users': 'Healthcare providers, radiologists, patients, and healthcare administrators',
                'business_context': 'B2B healthcare product requiring clinical validation and regulatory approval'
            }
        }
        
    def get_system_prompt(self, config_key='q_figurine_3d', context=None):
        # Check if context has selected experts (new multi-expert approach)
        if context and 'selected_experts' in context:
            return self.get_multi_expert_prompt(context['selected_experts'], context)
        
        # Otherwise use legacy approach for backward compatibility
        return self.get_system_prompt_legacy(config_key, context)
        
    def get_multi_expert_prompt(self, selected_experts=None, context=None):
        """Generate system prompt based on selected experts"""
        if not selected_experts:
            selected_experts = ['3d_graphics', 'ai_researcher', 'user_experience']  # Default
        
        expert_sections = []
        for expert_id in selected_experts:
            if expert_id in self.expert_profiles:
                expert = self.expert_profiles[expert_id]
                expert_sections.append(f"""{expert['emoji']} **{expert['title']}**
{expert['expertise']}""")
        
        experts_text = "\n\n".join(expert_sections)
        
        return f"""You are an AI PM Capability Consultant with {len(selected_experts)} expert perspectives:

{experts_text}

CORE MISSION: Help AI Product Managers identify what capabilities their AI models need to succeed.

FOCUS AREAS: For each capability discussion, address these four questions:
1. **Capability**: What specific AI model capability is needed?
2. **Description**: What does this capability mean in practical terms?
3. **User Value**: Why does this capability matter to end users?
4. **Technical Factors**: What are the key technical considerations?

RESPONSE GUIDELINES:
‚Ä¢ Keep responses concise (2-3 sentences per point)
‚Ä¢ Focus on AI model capabilities, not measurement methods
‚Ä¢ Avoid suggesting irrelevant capabilities (e.g., physical manufacturing tests for digital products)
‚Ä¢ Prioritize capabilities that directly impact user experience
‚Ä¢ Use clear, jargon-free language for business stakeholders

CONTENT MODIFICATION:
‚Ä¢ ADDING: Suggest missing AI capabilities that would benefit users
‚Ä¢ MODIFYING: Refine capability descriptions to be more precise
‚Ä¢ DELETING: Remove capabilities that don't align with AI model needs
‚Ä¢ PRIORITIZING: Rank capabilities by user impact and technical feasibility

EXPERT PERSPECTIVES:
{chr(10).join([f'‚Ä¢ {self.expert_profiles[eid]["emoji"]} {self.expert_profiles[eid]["title"]}: Focus on {self.expert_profiles[eid]["technical_focus"].split(",")[0].lower()}' for eid in selected_experts if eid in self.expert_profiles])}

Stay focused on identifying what AI models need to do, not how to test them."""

    def get_system_prompt_legacy(self, config_key='q_figurine_3d', context=None):
        """Legacy method for backward compatibility"""
        config = self.role_configs.get(config_key, self.role_configs['q_figurine_3d'])
        
        return f"""You are a Multi-Role AI Evaluation Consultant with expertise across three critical perspectives:

üé® DOMAIN SPECIALIST - {config['domain_specialist']['title']}
{config['domain_specialist']['expertise']}
Technical Focus: {config['domain_specialist']['technical_focus']}

üî¨ TECHNICAL RESEARCHER - {config['technical_researcher']['title']}  
{config['technical_researcher']['expertise']}
Technical Focus: {config['technical_researcher']['technical_focus']}

üë• USER ADVOCATE - {config['user_advocate']['title']}
{config['user_advocate']['expertise']}
Technical Focus: {config['user_advocate']['technical_focus']}

CURRENT DOMAIN: {config['domain']}
TARGET USERS: {config['target_users']}
BUSINESS CONTEXT: {config['business_context']}

CORE MISSION - CAPABILITY DECOMPOSITION:
Leverage your three specialist perspectives to decompose user needs into measurable model capabilities:
‚Ä¢ DOMAIN VIEW: What technical capabilities are essential for this specific domain?
‚Ä¢ RESEARCH VIEW: How can we measure and evaluate these capabilities scientifically? 
‚Ä¢ USER VIEW: What capabilities matter most to end users and drive business value?

MULTI-PERSPECTIVE ANALYSIS:
For each capability dimension, consider:
‚Ä¢ Domain Specialist: "Is this technically sound and domain-appropriate?"
‚Ä¢ Technical Researcher: "How do we measure this objectively and reliably?"
‚Ä¢ User Advocate: "Does this create real value for our target users?"

CONTENT MODIFICATION CAPABILITIES:
‚Ä¢ ADDING: Suggest new capabilities from domain, technical, or user perspectives
‚Ä¢ MODIFYING: Refine capabilities to balance technical feasibility with user value
‚Ä¢ DELETING: Remove capabilities that don't serve the domain, research goals, or user needs
‚Ä¢ PRIORITIZING: Rank capabilities considering all three perspectives

STRUCTURED RESPONSE FORMATS:
‚Ä¢ "From a DOMAIN perspective, I recommend ADDING [capability] because [domain reasoning]"
‚Ä¢ "As a TECHNICAL RESEARCHER, consider MODIFYING [capability] to improve [measurement/evaluation]"
‚Ä¢ "From the USER ADVOCATE view, you might DELETE [capability] since [user value reasoning]"
‚Ä¢ "Balancing all perspectives, let me REPRIORITIZE these based on [multi-perspective analysis]"

CONVERSATION STYLE:
‚Ä¢ Lead with the most relevant specialist perspective for each question
‚Ä¢ Always validate recommendations across all three roles
‚Ä¢ Use technical precision when discussing domain/research aspects
‚Ä¢ Use empathetic, value-focused language when discussing user aspects
‚Ä¢ Synthesize insights from all three perspectives for holistic recommendations"""

    def create_chat_session(self):
        return client.chats.create(
            model="gemini-2.0-flash-exp"
        )

consultant = EvaluationConsultant()

@app.route('/api/chat', methods=['POST'])
def chat():
    try:
        data = request.get_json()
        message = data.get('message', '')
        history = data.get('history', [])
        context = data.get('context', {})
        
        if not message:
            return jsonify({'error': 'Message is required'}), 400

        # Get config from context or use default
        config_key = context.get('domain_config', 'q_figurine_3d') if context else 'q_figurine_3d'
        
        # Create enhanced prompt with context
        enhanced_prompt = f"{consultant.get_system_prompt(config_key, context)}\n\n"
        
        if history:
            enhanced_prompt += "Previous conversation:\n"
            for msg in history[-5:]:  # Only include last 5 messages for context
                enhanced_prompt += f"{msg['role']}: {msg['content']}\n"
            enhanced_prompt += "\n"
        
        if context:
            enhanced_prompt += f"Current project context: {json.dumps(context)}\n\n"
        
        enhanced_prompt += f"User question: {message}\n\nPlease respond as the AI evaluation consultant:"

        if APP_MODE == 'demo':
            # ÊºîÁ§∫Ê®°ÂºèÔºö‰ΩøÁî®Ê®°ÊãüÂìçÂ∫î
            response_text = mock_generator.generate_chat_response(message)
        else:
            # Áîü‰∫ßÊ®°ÂºèÔºö‰ΩøÁî®ÁúüÂÆûAI API
            if not client:
                return jsonify({'error': 'AI client not initialized'}), 500
            
            # Generate response using Gemini
            response = client.models.generate_content(
                model="gemini-2.0-flash-exp",
                contents=enhanced_prompt
            )
            
            response_text = response.text
        
        return jsonify({
            'response': response_text,
            'timestamp': datetime.now().isoformat(),
            'status': 'success',
            'mode': APP_MODE
        })

    except Exception as e:
        print(f"Chat error: {str(e)}")
        return jsonify({'error': f'Failed to process chat message: {str(e)}'}), 500

@app.route('/api/chat/stream', methods=['POST'])
def chat_stream():
    def generate():
        try:
            data = request.get_json()
            message = data.get('message', '')
            history = data.get('history', [])
            context = data.get('context', {})
            
            if not message:
                yield f"data: {json.dumps({'error': 'Message is required'})}\n\n"
                return

            # Create chat session
            chat = consultant.create_chat_session()
            
            # Build context from history
            if history:
                for msg in history[-10:]:  # Include more history for better context
                    try:
                        if msg['role'] == 'user':
                            chat.send_message(msg['content'])
                        # Note: We can't add assistant messages to history in this way
                        # This is a limitation of the current Gemini API
                    except:
                        pass  # Continue if adding history fails
            
            # Get config from context or use default
            config_key = context.get('domain_config', 'q_figurine_3d') if context else 'q_figurine_3d'
            
            # Send current message and stream response
            response_stream = chat.send_message_stream(f"{consultant.get_system_prompt(config_key, context)}\n\nUser: {message}")
            
            full_response = ""
            for chunk in response_stream:
                if chunk.text:
                    full_response += chunk.text
                    yield f"data: {json.dumps({'type': 'chunk', 'content': chunk.text, 'timestamp': datetime.now().isoformat()})}\n\n"
            
            # Send completion
            yield f"data: {json.dumps({'type': 'complete', 'fullResponse': full_response, 'timestamp': datetime.now().isoformat()})}\n\n"
            
        except Exception as e:
            print(f"Streaming error: {str(e)}")
            yield f"data: {json.dumps({'type': 'error', 'error': str(e), 'timestamp': datetime.now().isoformat()})}\n\n"

    return Response(
        generate(),
        content_type='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Access-Control-Allow-Origin': '*',
        }
    )

@app.route('/api/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'healthy',
        'message': 'AI Evaluation Consultant API is running',
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/capabilities/modify', methods=['POST'])
def modify_capabilities():
    """Modify capability blueprint based on AI recommendations"""
    try:
        data = request.get_json()
        action = data.get('action')  # 'add', 'modify', 'delete', 'reprioritize'
        capability_data = data.get('capability_data', {})
        capability_id = data.get('capability_id')
        
        # Process different actions
        response_data = {
            'action': action,
            'success': True,
            'message': f'Successfully processed {action} action',
            'capability_data': capability_data
        }
        
        if action == 'add':
            response_data['message'] = f"Added new capability: {capability_data.get('title', 'Unknown')}"
        elif action == 'modify':
            response_data['message'] = f"Modified capability: {capability_data.get('title', 'Unknown')}"
        elif action == 'delete':
            response_data['message'] = f"Deleted capability with ID: {capability_id}"
        elif action == 'reprioritize':
            response_data['message'] = "Updated capability priorities"
            
        return jsonify(response_data)
        
    except Exception as e:
        print(f"Capability modification error: {str(e)}")
        return jsonify({'error': f'Failed to modify capabilities: {str(e)}', 'success': False}), 500

@app.route('/api/experts', methods=['GET'])
def get_experts():
    """Get available expert profiles for multi-expert consultation"""
    try:
        experts = {}
        for key, expert in consultant.expert_profiles.items():
            experts[key] = {
                'title': expert['title'],
                'emoji': expert['emoji'],
                'expertise': expert['expertise'],
                'technical_focus': expert['technical_focus'],
                'domains': expert['domains']
            }
        
        return jsonify({
            'experts': experts,
            'default_selection': ['3d_graphics', 'ai_researcher', 'user_experience'],
            'recommended_combinations': {
                'balanced': ['3d_graphics', 'ai_researcher', 'user_experience'],
                'technical_focus': ['3d_graphics', 'ai_researcher', 'safety_critical'],
                'user_focused': ['user_experience', 'ai_researcher', '3d_graphics'],
                'healthcare': ['medical_ai', 'healthcare_workflow', 'ai_researcher', 'safety_critical'],
                'autonomous_systems': ['autonomous_systems', 'safety_critical', 'ai_researcher', 'user_experience']
            }
        })
    except Exception as e:
        return jsonify({'error': f'Failed to get expert profiles: {str(e)}'}), 500

@app.route('/api/domain-configs', methods=['GET'])
def get_domain_configs():
    """Get available domain configurations for the multi-role consultant"""
    try:
        configs = {}
        for key, config in consultant.role_configs.items():
            configs[key] = {
                'domain': config['domain'],
                'target_users': config['target_users'], 
                'business_context': config['business_context'],
                'roles': {
                    'domain_specialist': config['domain_specialist']['title'],
                    'technical_researcher': config['technical_researcher']['title'],
                    'user_advocate': config['user_advocate']['title']
                }
            }
        
        return jsonify({
            'domain_configs': configs,
            'default_config': 'q_figurine_3d'
        })
    except Exception as e:
        return jsonify({'error': f'Failed to get domain configs: {str(e)}'}), 500

def extract_product_info_and_functions(user_input: str) -> dict:
    """Step 0: Information Extraction Agent - Intelligently parse user input"""
    
    if APP_MODE == 'demo':
        # ÊºîÁ§∫Ê®°ÂºèÔºö‰ΩøÁî®Ê®°ÊãüÊï∞ÊçÆ
        return {
            'productInfo': f"Demo product based on: {user_input}",
            'idealFunctions': f"Demo functions based on: {user_input}"
        }
    
    # Áîü‰∫ßÊ®°ÂºèÔºö‰ΩøÁî®ÁúüÂÆûAI API
    if not client:
        raise ValueError("AI client not initialized for production mode")
    
    extraction_prompt = f"""# ROLE: ‰∫ßÂìÅÈúÄÊ±Ç‰ø°ÊÅØÊèêÂèñ‰∏ìÂÆ∂ (Product Requirements Extraction Specialist)

# CONTEXT:
‰Ω†ÊòØ‰∏Ä‰∏™‰∏ìÈó®‰ªéÁî®Êà∑ÊèèËø∞‰∏≠ÊèêÂèñÁªìÊûÑÂåñ‰∫ßÂìÅ‰ø°ÊÅØÁöÑAIÂä©Êâã„ÄÇÁî®Êà∑ÂèØËÉΩ‰ºöÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊ∑∑ÂêàÊèèËø∞‰∫ßÂìÅ‰ø°ÊÅØÂíåÊúüÊúõÂäüËÉΩÔºå‰Ω†ÁöÑ‰ªªÂä°ÊòØÂ∞ÜËøô‰∫õ‰ø°ÊÅØÊ∏ÖÊô∞Âú∞ÂàÜÁ¶ªÂíåÁªÑÁªá„ÄÇ

# TASK:
ÂàÜÊûêÁî®Êà∑Êèê‰æõÁöÑËæìÂÖ•ÔºåÂ∞ÜÂÖ∂Êô∫ËÉΩÂú∞ÂàÜÁ¶ª‰∏∫‰∏§‰∏™Ê†∏ÂøÉÈÉ®ÂàÜÔºö
1. **‰∫ßÂìÅ‰ø°ÊÅØ (Product Information)**: ‰∫ßÂìÅÁöÑÂü∫Êú¨‰ø°ÊÅØ„ÄÅËÉåÊôØ„ÄÅÂÆö‰Ωç„ÄÅÁõÆÊ†áÁî®Êà∑Á≠â
2. **ÁêÜÊÉ≥ÂäüËÉΩ (Ideal Functions)**: Áî®Êà∑ÊúüÊúõÁöÑÂÖ∑‰ΩìÂäüËÉΩ„ÄÅÁâπÊÄß„ÄÅËÉΩÂäõÈúÄÊ±ÇÁ≠â

# INPUT:
Áî®Êà∑ËæìÂÖ•: {user_input}

# OUTPUT CONSTRAINTS (MANDATORY):
1. ‰Ω†ÂøÖÈ°ª‰∏îÂè™ËÉΩËøîÂõû‰∏Ä‰∏™Á¨¶Âêà‰ª•‰∏ãJSON SchemaÁöÑ **Âçï‰∏ÄJSONÂØπË±°**„ÄÇ‰∏çË¶ÅÂåÖÂê´‰ªª‰ΩïJSONÂå∫Âùó‰πãÂ§ñÁöÑËß£ÈáäÊÄßÊñáÊú¨„ÄÇ
2. Â¶ÇÊûúÁî®Êà∑ËæìÂÖ•‰∏≠ÊüêÈÉ®ÂàÜ‰ø°ÊÅØ‰∏çÊòéÁ°ÆÔºåËØ∑Âü∫‰∫é‰∏ä‰∏ãÊñáËøõË°åÂêàÁêÜÊé®Êñ≠„ÄÇ
3. Á°Æ‰øù‰∏§‰∏™Â≠óÊÆµÈÉΩÊúâÂÆûË¥®ÊÄßÂÜÖÂÆπÔºå‰∏çËÉΩ‰∏∫Á©∫„ÄÇ

# JSON SCHEMA (Strictly Enforce):
{{
  "productInfo": "string (‰∫ßÂìÅÁöÑÂü∫Êú¨‰ø°ÊÅØ„ÄÅËÉåÊôØ„ÄÅÂÆö‰Ωç„ÄÅÁî®Êà∑Áæ§‰ΩìÁ≠â)",
  "idealFunctions": "string (ÊúüÊúõÁöÑÂäüËÉΩ„ÄÅÁâπÊÄß„ÄÅËÉΩÂäõÈúÄÊ±ÇÁ≠â)"
}}

# EXAMPLES:

ËæìÂÖ•: "ÊàëÊÉ≥ÂÅö‰∏Ä‰∏™3DÂ§¥ÂÉèÁîüÊàêÂô®ÔºåÁî®Êà∑‰∏ä‰º†ÁÖßÁâáÂ∞±ËÉΩÁîüÊàêÂç°ÈÄöÁâà3DÊ®°ÂûãÔºå‰∏ªË¶ÅÈù¢ÂêëÁ§æ‰∫§Â™í‰ΩìÁî®Êà∑ÔºåÂ∏åÊúõÊ®°ÂûãË¥®ÈáèÈ´ò„ÄÅÈ£éÊ†º‰∏ÄËá¥„ÄÅËÉΩÂø´ÈÄüÁîüÊàê„ÄÇ"

ËæìÂá∫:
{{
  "productInfo": "3DÂ§¥ÂÉèÁîüÊàêÂô®‰∫ßÂìÅÔºåÈÄöËøáÁî®Êà∑‰∏ä‰º†ÁöÑÁÖßÁâáÁîüÊàêÂç°ÈÄöÁâà3DÊ®°ÂûãÔºå‰∏ªË¶ÅÁõÆÊ†áÁî®Êà∑ÊòØÁ§æ‰∫§Â™í‰ΩìÁî®Êà∑ÔºåÁî®‰∫é‰∏™‰∫∫Â§¥ÂÉèÂíåÂàÜ‰∫´ÈúÄÊ±Ç„ÄÇ",
  "idealFunctions": "È´òË¥®Èáè3DÊ®°ÂûãÁîüÊàê„ÄÅÈ£éÊ†º‰∏ÄËá¥ÁöÑÂç°ÈÄöÂåñÂ§ÑÁêÜ„ÄÅÂø´ÈÄüÁîüÊàêÂìçÂ∫î„ÄÅÊîØÊåÅÂ§öÁßçÁÖßÁâáËæìÂÖ•Ê†ºÂºè„ÄÅÈÄÇÂêàÁ§æ‰∫§Â™í‰ΩìÂàÜ‰∫´ÁöÑËæìÂá∫Ê†ºÂºè„ÄÇ"
}}"""

    try:
        response = client.models.generate_content(
            model="gemini-2.0-flash-exp",
            contents=extraction_prompt
        )
        
        response_text = response.text.strip()
        
        # Try to extract JSON from the response
        import re
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            return json.loads(json_str)
        else:
            # Fallback: if extraction fails, use the original input for both
            return {
                "productInfo": user_input,
                "idealFunctions": user_input
            }
            
    except Exception as e:
        print(f"Information extraction error: {str(e)}")
        # Fallback: if extraction fails, use the original input for both
        return {
            "productInfo": user_input,
            "idealFunctions": user_input
        }

def call_domain_router_agent(product_info: str, ideal_functions: str) -> dict:
    """Step A: Domain Router Agent - Identifies required expert knowledge domains"""
    
    if APP_MODE == 'demo':
        # ÊºîÁ§∫Ê®°ÂºèÔºö‰ΩøÁî®Ê®°ÊãüÊï∞ÊçÆ
        return {
            'primary_domain': '3D Computer Vision',
            'secondary_domains': ['Machine Learning', 'User Experience'],
            'domain_config': 'q_figurine_3d'
        }
    
    # Áîü‰∫ßÊ®°ÂºèÔºö‰ΩøÁî®ÁúüÂÆûAI API
    if not client:
        raise ValueError("AI client not initialized for production mode")
    
    print(f"[DEBUG] Domain router called with product_info: {product_info[:50]}...")
    print(f"[DEBUG] Domain router called with ideal_functions: {ideal_functions[:50]}...")
    
    print(f"[DEBUG] Building domain router prompt...")
    domain_router_prompt = f"""# ROLE: È¶ñÂ∏≠Á≥ªÁªüÊû∂ÊûÑÂ∏à (Chief Systems Architect) & ‰∏ìÂÆ∂Ë∞ÉÂ∫¶‰∏≠Êû¢

# CONTEXT:
‰Ω†ÊòØ‰∏Ä‰∏™AIËØÑÊµãÁ≥ªÁªüÁöÑ"Ë∑ØÁî±"‰∏≠Êû¢„ÄÇ‰Ω†ÁöÑ‰ªªÂä°ÊòØÂàÜÊûê‰∏Ä‰∏™Êñ∞‰∫ßÂìÅÁöÑÈ´òÈò∂ÈúÄÊ±ÇÔºåÂπ∂ÂáÜÁ°ÆÂà§Êñ≠ÔºöË¶Å"ËØÑÊµã"Ëøô‰∏™‰∫ßÂìÅÔºåÊàë‰ª¨ÂøÖÈ°ª‰ªéÂì™‰∫õ"‰∏ì‰∏öÈ¢ÜÂüü"ËßÜËßíÂàáÂÖ•„ÄÇ

# TASK:
ÂàÜÊûêÁî®Êà∑Êèê‰æõÁöÑ [‰∫ßÂìÅ‰ø°ÊÅØ] Âíå [ÁêÜÊÉ≥ÂäüËÉΩ]„ÄÇ‰Ω†ÂøÖÈ°ªËØÜÂà´Âá∫‰∏â‰∏™ÂÖ≥ÈîÆÁöÑÁü•ËØÜÈ¢ÜÂüüÔºö

# INPUT:
[‰∫ßÂìÅ‰ø°ÊÅØ]: {product_info}
[ÁêÜÊÉ≥ÂäüËÉΩ]: {ideal_functions}

# TASK:
ÂàÜÊûêÁî®Êà∑Êèê‰æõÁöÑ [‰∫ßÂìÅ‰ø°ÊÅØ] Âíå [ÁêÜÊÉ≥ÂäüËÉΩ]„ÄÇ‰Ω†ÂøÖÈ°ªËØÜÂà´Âá∫‰∏â‰∏™ÂÖ≥ÈîÆÁöÑÁü•ËØÜÈ¢ÜÂüüÔºö
1. ‰∏ì‰∏ö/‰∏öÂä°È¢ÜÂüü (Professional/Business Domain): Âç≥ËØ•‰∫ßÂìÅÊâÄÂ±ûÁöÑË°å‰∏öÊ†∏ÂøÉ‰ª∑ÂÄº„ÄÇ (‰æãÂ¶ÇÔºöÁîµÂΩ±Âà∂‰Ωú„ÄÅÂπøÂëäËê•ÈîÄ„ÄÅÂåªÁñóËØäÊñ≠„ÄÅÊ∏∏ÊàèËÆæËÆ°)„ÄÇ
2. ÊäÄÊúØÂÆûÁé∞È¢ÜÂüü (Technical Domain): Âç≥ÊîØÊíëËØ•‰∫ßÂìÅÁöÑÊ†∏ÂøÉÊäÄÊúØÊ†à„ÄÇ (‰æãÂ¶ÇÔºöÂÆûÊó∂Ê∏≤ÊüìÁÆ°Á∫ø„ÄÅÁâ©ÁêÜ‰ªøÁúü„ÄÅAIGCÁîüÊàêÁÆóÊ≥ï„ÄÅÁîüÁâ©‰ø°ÊÅØÂ≠¶)„ÄÇ
3. Ê†∏ÂøÉÁî®Êà∑‰ª∑ÂÄº (Core User Value / Persona): Âç≥Áî®Êà∑‰ΩøÁî®ËØ•‰∫ßÂìÅÁöÑÊ†∏ÂøÉÈ©±Âä®Âäõ„ÄÇ (‰æãÂ¶ÇÔºöËøΩÊ±ÇÊÉÖÊÑüÂÖ±È∏£„ÄÅËøΩÊ±ÇÁîü‰∫ßÂäõÊïàÁéá„ÄÅËøΩÊ±ÇÂïÜ‰∏öÂèòÁé∞)„ÄÇ

# INPUT (User will provide):
[‰∫ßÂìÅ‰ø°ÊÅØ]: {product_info}
[ÁêÜÊÉ≥ÂäüËÉΩ]: {ideal_functions}

# OUTPUT CONSTRAINTS (MANDATORY):
1. ‰Ω†ÂøÖÈ°ª‰∏îÂè™ËÉΩËøîÂõû‰∏Ä‰∏™Á¨¶Âêà‰ª•‰∏ãJSON SchemaÁöÑ **Âçï‰∏ÄJSONÂØπË±°**„ÄÇ‰∏çË¶ÅÂåÖÂê´‰ªª‰ΩïJSONÂå∫Âùó‰πãÂ§ñÁöÑËß£ÈáäÊÄßÊñáÊú¨„ÄÇ
2. `knowledgeDescription` ÂøÖÈ°ªÊòØÁ≤æÁÇºÁöÑÁü≠ËØ≠ÔºåÁî®‰∫é"Ê≥®ÂÖ•"Áªô‰∏ã‰∏Ä‰∏™Agent‰Ωú‰∏∫Êåá‰ª§„ÄÇ

# JSON SCHEMA (Strictly Enforce):
{{
  "professionalDomain": {{
    "domainName": "string (‰æãÂ¶Ç: ÂπøÂëäËê•ÈîÄ‰∏éÁóÖÊØíÂºè‰º†Êí≠)",
    "knowledgeDescription": "string (ÊèèËø∞ËØ•È¢ÜÂüüÁöÑÊ†∏ÂøÉÁü•ËØÜÁÇπÔºå‰æãÂ¶Ç: Á≤æÈÄöËßÜËßâÈî§„ÄÅÈªÑÈáë3ÁßíÂê∏ÂºïÂäõÊ≥ïÂàô„ÄÅA/BÊµãËØïÂíåCTRËΩ¨ÂåñÊºèÊñó)"
  }},
  "technicalDomain": {{
    "domainName": "string (‰æãÂ¶Ç: 3DËßÜÈ¢ëAIGCÁÆ°Á∫ø)",
    "knowledgeDescription": "string (ÊèèËø∞ËØ•È¢ÜÂüüÁöÑÊ†∏ÂøÉÊäÄÊúØÁÇπÔºå‰æãÂ¶Ç: Á≤æÈÄö3DËµÑ‰∫ßÁîüÊàê„ÄÅÂä®ÊÄÅÁªëÂÆö„ÄÅÂú∫ÊôØÊ∏≤Êüì‰∏éËßÜÈ¢ëÂêàÊàêÊäÄÊúØ)"
  }},
  "userDomain": {{
    "domainName": "string (‰æãÂ¶Ç: Â∏ÇÂú∫ÈÉ®ÁªèÁêÜ (User Persona))",
    "knowledgeDescription": "string (ÊèèËø∞ËØ•Áî®Êà∑ÊúÄÂÖ≥ÂøÉ‰ªÄ‰πàÔºå‰æãÂ¶Ç: Ê∑±ÂàªÁêÜËß£Áî®Êà∑ÂØπ'ROIÊúÄÂ§ßÂåñ'Âíå'ÂìÅÁâåÂÆâÂÖ®'ÁöÑÁªàÊûÅÈúÄÊ±Ç)"
  }}
}}"""

    try:
        print("[DEBUG] Calling Gemini API for domain router...")
        response = client.models.generate_content(
            model="gemini-2.0-flash-exp",
            contents=domain_router_prompt
        )
        
        print(f"[DEBUG] API call successful. Response type: {type(response)}")
        if hasattr(response, 'text'):
            response_text = response.text.strip()
            print(f"[DEBUG] Raw domain router response: {response_text}")
        else:
            print(f"[DEBUG] Response has no text attribute: {response}")
            raise ValueError("No text in API response")
        
        # Try to extract JSON from the response (handle markdown code blocks)
        import re
        
        # First try to remove markdown code block markers
        if '```json' in response_text:
            print("[DEBUG] Detected markdown code block in domain router response")
            # Extract content between ```json and ```
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
                print(f"[DEBUG] Extracted JSON string from domain router: {json_str[:100]}...")
            else:
                # Fallback to normal JSON extraction
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    raise ValueError("No valid JSON found in domain router response")
        else:
            # Normal JSON extraction
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
            else:
                raise ValueError("No valid JSON found in domain router response")
        
        return json.loads(json_str)
            
    except Exception as e:
        print(f"Domain router error: {str(e)}")
        raise e

def call_dynamic_expert_agent(domain_context: dict, product_info: str, ideal_functions: str) -> list:
    """ÈáçÊûÑÂêéÁöÑËÉΩÂäõÁª¥Â∫¶ÁîüÊàê - ÊîØÊåÅÊºîÁ§∫Ê®°ÂºèÂíåÁúüÂÆûÊ®°Âºè"""
    
    # ÁîüÊàêÊâßË°åID
    execution_id = f"capability_gen_{int(time.time())}"
    
    # ÂºÄÂßãÁõëÊéßÊâßË°å
    workflow_monitor.start_execution(execution_id, {
        'product_info': product_info,
        'ideal_functions': ideal_functions,
        'domain_context': domain_context,
        'mode': APP_MODE
    })
    
    try:
        if APP_MODE == 'demo':
            # ÊºîÁ§∫Ê®°ÂºèÔºö‰ΩøÁî®Ê®°ÊãüÊï∞ÊçÆ
            workflow_monitor.add_step("Demo Mode", {
                'action': 'Generating mock capability dimensions',
                'mode': 'demo',
                'note': 'Using pre-generated realistic data for demonstration'
            })
            
            # Ê®°ÊãüÂ§ÑÁêÜÊó∂Èó¥
            import time
            time.sleep(1)  # Ê®°ÊãüAIÂ§ÑÁêÜÊó∂Èó¥
            
            # ÁîüÊàêÊ®°ÊãüÊï∞ÊçÆ
            result = mock_generator.generate_capability_dimensions(product_info, ideal_functions)
            
            workflow_monitor.add_step("Mock Data Generated", {
                'action': 'Mock capability dimensions generated',
                'dimensions_count': len(result),
                'dimensions': [{'id': dim.get('id'), 'title': dim.get('title')} for dim in result]
            })
            
        else:
            # Áîü‰∫ßÊ®°ÂºèÔºö‰ΩøÁî®ÁúüÂÆûAI API
            # Ê≠•È™§1: Âä†ËΩΩÊèêÁ§∫ËØç
            workflow_monitor.add_step("Load Prompt Template", {
                'action': 'Loading capability dimensions prompt template',
                'template_source': 'prompts/capability_dimensions_prompt.txt'
            })
            
            # ‰ΩøÁî®ÊèêÁ§∫ËØçÁÆ°ÁêÜÂô®Âä†ËΩΩÂíåÊ†ºÂºèÂåñÊèêÁ§∫ËØç
            dynamic_expert_prompt = prompt_manager.format_capability_dimensions_prompt(
                product_info=product_info,
                ideal_functions=ideal_functions
            )
            
            # Ê≠•È™§2: Ë∞ÉÁî®AIÊ®°Âûã
            workflow_monitor.add_step("Call AI Model", {
                'action': 'Calling Gemini 2.5 Pro model',
                'model': 'gemini-2.5-pro',
                'prompt_length': len(dynamic_expert_prompt)
            })
            
            response = client.models.generate_content(
                model="gemini-2.5-pro",
                contents=dynamic_expert_prompt
            )
            
            response_text = response.text.strip()
            
            # Ê≠•È™§3: Ëß£ÊûêÂìçÂ∫î
            workflow_monitor.add_step("Parse AI Response", {
                'action': 'Extracting JSON from AI response',
                'response_length': len(response_text)
            })
            
            # Try to extract JSON from the response (handle markdown code blocks)
            import re
            
            # First try to remove markdown code block markers
            if '```json' in response_text:
                # Extract content between ```json and ```
                json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1).strip()
                else:
                    # Fallback to normal JSON extraction
                    json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
                    if json_match:
                        json_str = json_match.group(0)
                    else:
                        raise ValueError("No valid JSON found in dynamic expert response")
            else:
                # Normal JSON extraction
                json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    raise ValueError("No valid JSON found in dynamic expert response")
            
            # Ê≠•È™§4: È™åËØÅÂíåËøîÂõûÁªìÊûú
            result = json.loads(json_str)
            
            workflow_monitor.add_step("Validate Results", {
                'action': 'Validating generated capability dimensions',
                'dimensions_count': len(result),
                'dimensions': [{'id': dim.get('id'), 'title': dim.get('title')} for dim in result]
            })
        
        # ÂÆåÊàêÊâßË°å
        workflow_monitor.complete_execution({
            'capability_dimensions': result,
            'total_dimensions': len(result),
            'execution_time': datetime.now().isoformat(),
            'mode': APP_MODE
        })
        
        return result
            
    except Exception as e:
        print(f"Dynamic expert error: {str(e)}")
        
        # ËÆ∞ÂΩïÈîôËØØ
        workflow_monitor.complete_execution(
            output_data=None,
            error=str(e)
        )
        
        raise e

@app.route('/api/generate-capability-dimensions', methods=['POST'])
def generate_capability_dimensions():
    """V3: Three-stage AI workflow with intelligent input extraction"""
    try:
        data = request.get_json()
        
        # Check if we have structured input or need to extract
        product_info = data.get('productInfo', '')
        ideal_functions = data.get('idealFunctions', '')
        user_input = data.get('userInput', '')
        
        # If we don't have structured input, extract from userInput
        if not product_info or not ideal_functions:
            if not user_input:
                return jsonify({'error': 'Either structured (productInfo + idealFunctions) or unstructured (userInput) input is required'}), 400
            
            # Step 0: Extract product info and ideal functions using AI
            print("Step 0: Extracting product information and ideal functions...")
            extracted_info = extract_product_info_and_functions(user_input)
            product_info = extracted_info.get('productInfo', user_input)
            ideal_functions = extracted_info.get('idealFunctions', user_input)
            print(f"Extracted - Product Info: {product_info[:100]}...")
            print(f"Extracted - Ideal Functions: {ideal_functions[:100]}...")

        # Step A: Call Domain Router Agent
        print("Step A: Calling Domain Router Agent...")
        domain_context = call_domain_router_agent(product_info, ideal_functions)
        print(f"Domain context identified: {domain_context}")
        
        # Step B & C: Call Dynamic Expert Agent with injected context
        print("Step B & C: Calling Dynamic Expert Agent with injected expertise...")
        blueprint_cards = call_dynamic_expert_agent(domain_context, product_info, ideal_functions)
        print(f"Generated {len(blueprint_cards)} capability dimensions")
        
        return jsonify({
            'blueprintCards': blueprint_cards,
            'extractedInfo': {  # Return extracted info for debugging/verification
                'productInfo': product_info,
                'idealFunctions': ideal_functions
            },
            'domainContext': domain_context,  # Optional: Return for debugging
            'timestamp': datetime.now().isoformat(),
            'status': 'success'
        })
            
    except Exception as e:
        print(f"Capability dimensions generation error: {str(e)}")
        return jsonify({'error': f'Failed to generate capability dimensions: {str(e)}'}), 500

@app.route('/api/generate-blueprint', methods=['POST'])
def generate_blueprint():
    """Legacy endpoint - redirects to new two-stage workflow"""
    try:
        data = request.get_json()
        user_input = data.get('userInput', '')
        
        if not user_input:
            return jsonify({'error': 'User input is required'}), 400
        
        # Step 0: Extract product info and ideal functions using AI
        print("Step 0: Extracting product information and ideal functions...")
        extracted_info = extract_product_info_and_functions(user_input)
        product_info = extracted_info.get('productInfo', user_input)
        ideal_functions = extracted_info.get('idealFunctions', user_input)
        print(f"Extracted - Product Info: {product_info[:100]}...")
        print(f"Extracted - Ideal Functions: {ideal_functions[:100]}...")
        
        # Call the new three-stage workflow
        return generate_capability_dimensions_internal(product_info, ideal_functions)
            
    except Exception as e:
        print(f"Blueprint generation error: {str(e)}")
        return jsonify({'error': f'Failed to generate blueprint: {str(e)}'}), 500

def generate_capability_dimensions_internal(product_info: str, ideal_functions: str):
    """Internal function to avoid code duplication"""
    try:
        # Step A: Call Domain Router Agent
        domain_context = call_domain_router_agent(product_info, ideal_functions)
        
        # Step B & C: Call Dynamic Expert Agent with injected context
        blueprint_cards = call_dynamic_expert_agent(domain_context, product_info, ideal_functions)
        
        return jsonify({
            'blueprintCards': blueprint_cards,
            'domainContext': domain_context,
            'timestamp': datetime.now().isoformat(),
            'status': 'success'
        })
        
    except Exception as e:
        raise e

@app.route('/api/mode', methods=['GET'])
def get_mode():
    """Get current application mode"""
    return jsonify({
        'mode': APP_MODE,
        'is_demo': APP_MODE == 'demo',
        'is_production': APP_MODE == 'production'
    })

@app.route('/api/mode', methods=['POST'])
def set_mode():
    """Set application mode (requires restart)"""
    try:
        data = request.get_json()
        new_mode = data.get('mode', '').lower()
        
        if new_mode not in ['demo', 'production']:
            return jsonify({'error': 'Invalid mode. Must be "demo" or "production"'}), 400
        
        return jsonify({
            'message': f'Mode will be set to {new_mode} on next restart',
            'current_mode': APP_MODE,
            'new_mode': new_mode,
            'note': 'Please restart the application for changes to take effect'
        })
        
    except Exception as e:
        return jsonify({'error': f'Failed to set mode: {str(e)}'}), 500

@app.route('/api/templates', methods=['GET'])
def get_templates():
    """Get evaluation templates for different scenarios"""
    templates = [
        {
            "id": "ideal-output",
            "title": "Ideal Output Definition",
            "description": "Define what perfect model outputs should look like for your use case",
            "prompt": "I need to build an evaluation system for [Feature Name]. Help me define: 1. What does the ideal output look like? 2. What are the key quality dimensions I should measure? 3. What are the common failure modes I need to prevent?"
        },
        {
            "id": "user-feedback",
            "title": "User Feedback Analysis", 
            "description": "Analyze user complaints and feedback to identify improvement areas",
            "prompt": "I have collected user feedback about [Feature/Product Name]. Please help me: 1. Identify main user pain points 2. Translate complaints into technical requirements 3. Prioritize issues based on user impact 4. Suggest specific evaluation metrics"
        },
        {
            "id": "competitor-analysis",
            "title": "Competitor Analysis",
            "description": "Compare your model performance against competitors and benchmarks", 
            "prompt": "I want to benchmark [Your Product] against competitors. Help me: 1. Define evaluation criteria for competitive positioning 2. Identify key differentiators 3. Set target performance levels 4. Create head-to-head comparison frameworks"
        },
        {
            "id": "model-iteration",
            "title": "Model Iteration Eval",
            "description": "Set up evaluation frameworks for iterative model improvements",
            "prompt": "I'm working on iterative improvements for [Model Name]. Help me design: 1. Regression testing criteria 2. Progressive evaluation metrics 3. A/B testing frameworks 4. Success criteria for each iteration"
        }
    ]
    
    return jsonify({'templates': templates})

if __name__ == '__main__':
    print("Starting AI Evaluation Consultant API...")
    print(f"Application mode: {APP_MODE.upper()}")
    if APP_MODE == 'production':
        print(f"Gemini API configured: {'Yes' if GEMINI_API_KEY else 'No'}")
    else:
        print("Running in demo mode with mock data")
    app.run(debug=True, host='0.0.0.0', port=8080)